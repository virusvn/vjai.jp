<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>Hoáº¡t Ä‘á»™ng - VJAI - Cá»™ng Ä‘á»“ng AI Viá»‡t Nam táº¡i Nháº­t Báº£n</title>
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="icon" href="https://vjai.jpfavicon.png">

  
  <link rel="stylesheet" href="/css/style.min.3e25e0d8b6702e00684d9a35cfc1f3461ff28f5139aa60ece211c234673b3fdd.css">

  

</head>

<body class='page page-default-list'>
  <div id="main-menu-mobile" class="main-menu-mobile">
  <ul>
    
    
    <li class="menu-item-giá»›i thiá»‡u">
      <a href="/about/">
        
        <span>Giá»›i thiá»‡u</span>
      </a>
    </li>
    
    <li class="menu-item-hoáº¡t Ä‘á»™ng active">
      <a href="/activities/">
        
        <span>Hoáº¡t Ä‘á»™ng</span>
      </a>
    </li>
    
    <li class="menu-item-khoÃ¡ há»c">
      <a href="/courses/">
        
        <span>KhoÃ¡ há»c</span>
      </a>
    </li>
    
    <li class="menu-item-papers">
      <a href="/papers/">
        
        <span>Papers</span>
      </a>
    </li>
    
    <li class="menu-item-thÃ nh viÃªn">
      <a href="/team/">
        
        <span>ThÃ nh viÃªn</span>
      </a>
    </li>
    
    <li class="menu-item-tin tá»©c">
      <a href="/news/">
        
        <span>Tin tá»©c</span>
      </a>
    </li>
    
  </ul>
</div>
  <div class="wrapper">
    <div class='header'>
  <div class="container">
    <div class="logo">
      <a href="https://vjai.jp"><img alt="Figurit Homepage" src="https://vjai.jpimages/logo.svg" /></a>
    </div>
    <div class="logo-mobile">
      <a href="https://vjai.jp"><img alt="Figurit Homepage" src="https://vjai.jpimages/logo-mobile.svg" /></a>
    </div>
    <div id="main-menu" class="main-menu">
  <ul>
    
    
    <li class="menu-item-giá»›i thiá»‡u">
      <a href="/about/">
        
        <span>Giá»›i thiá»‡u</span>
      </a>
    </li>
    
    <li class="menu-item-hoáº¡t Ä‘á»™ng active">
      <a href="/activities/">
        
        <span>Hoáº¡t Ä‘á»™ng</span>
      </a>
    </li>
    
    <li class="menu-item-khoÃ¡ há»c">
      <a href="/courses/">
        
        <span>KhoÃ¡ há»c</span>
      </a>
    </li>
    
    <li class="menu-item-papers">
      <a href="/papers/">
        
        <span>Papers</span>
      </a>
    </li>
    
    <li class="menu-item-thÃ nh viÃªn">
      <a href="/team/">
        
        <span>ThÃ nh viÃªn</span>
      </a>
    </li>
    
    <li class="menu-item-tin tá»©c">
      <a href="/news/">
        
        <span>Tin tá»©c</span>
      </a>
    </li>
    
  </ul>
</div>
    <button id="toggle-main-menu-mobile" class="hamburger hamburger--slider" role="presentation" aria-label="mobile menu trigger">
  <span class="hamburger-box">
    <span class="hamburger-inner"></span>
  </span>
</button>
  </div>
</div>
    
<div class="intro">
  <div class="container">
    <div class="row">
      <div class="col-12">
        

<h1 id="vietnam-japan-ai-community">Vietnam Japan AI Community</h1>

<p>Cá»™ng Ä‘á»“ng ngÆ°á»i Viá»‡t yÃªu thÃ­ch vÃ  Ä‘ang lÃ m viá»‡c vá» AI á»Ÿ Nháº­t Báº£n.</p>

      </div>
    </div>
  </div>
</div>

<div class="container pb-6">
  <div class="row">
    
    <div class="col-12 col-md-6 mb-2 "><p>Chá»§ Ä‘á»: Cycle Gan
Diá»…n giáº£: VÄƒn PhÃº Quang Huy
Äá»‹a Ä‘iá»ƒm: cty CookPad (cty cá»§a diá»…n giáº£)
    Do khÃ´ng Ä‘áº·t dc Ä‘á»‹a Ä‘iá»ƒm nhÆ° thÆ°á»ng lá»‡ nÃªn btc Ä‘Ã£ nhá» báº¡n Huy
    Ä‘áº·t há»™ phÃ²ng cá»§a cty.</p>

<p>ThÃ¡ng 10 sáº½ tiáº¿p tá»¥c thÃ¡ng 9 vá»›i 1 bÃ i ná»¯a vá» GANs vÃ¬ vá» cÆ¡ báº£n GANs Ä‘ang khÃ¡ lÃ  HOT.
Chá»§ Ä‘á» cá»§a thÃ¡ng 10 sáº½ lÃ  CYCLEGANs
CycleGAN lÃ  thuáº­t toÃ¡n dá»±a trÃªn GAN Ä‘á»ƒ biáº¿n áº£nh nÃ y sang áº£nh khÃ¡c chá»‰ thay Ä‘á»•i bá» máº·t cá»§a váº­t thá»ƒ mÃ  váº«n giá»¯ nguyÃªn bá»‘ cá»¥c. Cháº³ng háº¡n cÃ³ thá»ƒ chuyá»ƒn tá»« áº£nh ngá»±a thÆ°á»ng sang ngá»±a váº±n, chuyá»ƒn áº£nh cam thÃ nh áº£nh tÃ¡o, chuyá»ƒn áº£nh thÃ nh tranh&hellip;
Äá»ƒ biáº¿t thÃªm cÃ¡c á»©ng dá»¥ng cá»§a CycleGAN, cÃ¡c báº¡n cÃ³ thá»ƒ tham kháº£o á»Ÿ trang chá»§: <a href="https://junyanz.github.io/CycleGAN/">https://junyanz.github.io/CycleGAN/</a>.
Luáº­n vÄƒn gá»‘c cá»§a CycleGAN táº¡i Ä‘Ã¢y: <a href="https://arxiv.org/abs/1703.10593">https://arxiv.org/abs/1703.10593</a>
Demo cá»§a tÃ¡c giáº£ paper: <a href="https://youtu.be/9reHvktowLY">https://youtu.be/9reHvktowLY</a></p>

<p>VÃ  diá»…n giáº£ Huy cÃ³ thá»ƒ cÅ©ng sáº½ mang Ä‘áº¿n cho chÃºng ta 1 demo nho nhá».
HÃ£y cÃ¹ng Ä‘áº¿n tranh luáº­n nÃ o !!</p>
</div>
    
    <div class="col-12 col-md-6 mb-2 "><p>Thá»i gian: 14h~18h Thá»© Báº£y - 13/04/2019 (má»Ÿ cá»­a Ä‘Ã³n khÃ¡ch 13h40 ~ 13h55)</p>

<p>ğŸ‘‰ Form Ä‘Äƒng kÃ½ tham dá»±: <a href="https://forms.gle/rXFu9H4i8aga3Mxi6">https://forms.gle/rXFu9H4i8aga3Mxi6</a> (Háº¡n cuá»‘i Ä‘Äƒng kÃ½ lÃ  23:59 ngÃ y 8/4/2019)</p>

<p>Tiáº¿p ná»‘i thÃ nh cÃ´ng cá»§a VJAI Minicourse, VJAI meetup sáº½ trá»Ÿ láº¡i vÃ o ngÃ y 13/4/2019. Ná»™i dung cá»§a buá»•i Meetup #15 nhÆ° sau:</p>

<p>14:00 â€“ 15:00 Deep learning in healthcare: Opportunities and challenges with electronic health records (EHR) data. (Tráº§n Quang Thiá»‡n, University of Tsukuba)
15:00 â€“ 16:00 Machine learning aided biomolecular design: from understanding functions to virtual screening (Dr. Tráº§n PhÆ°á»›c Duy, Tokyo Institute of Technology)
16:00 â€“ 16:15 Break
16:15 â€“ 16:30 Introduction to AI research at MILA (Nguyen XuÃ¢n Phong, Hitachi &amp; Tokyo Techies)
16:30 â€“ 18:00 Panel Discussion with Special Guest Dr. BÃ¹i Háº£i HÆ°ng (VinAI &amp; Deepmind)</p>

<p>ğŸ¢ Äá»‹a Ä‘iá»ƒm: Rakuten Inc. ã€’158-0094 æ±äº¬éƒ½ä¸–ç”°è°·åŒºç‰å·ï¼‘ä¸ç›®ï¼‘ï¼”âˆ’ï¼‘ â„¹ï¸ Access: æ±æ€¥ç”°åœ’éƒ½å¸‚ç·šã€æ±æ€¥å¤§äº•ç”ºç·šã€ŒäºŒå­ç‰å·ã€é§…ã‚ˆã‚Šå¾’æ­©4åˆ†</p>

<p>ThÃ´ng tin vá» Ä‘á»‹a chá»‰ vÃ  cÃ¡ch Ä‘i: <a href="https://corp.rakuten.co.jp/about/map/crimsonhouse/">https://corp.rakuten.co.jp/about/map/crimsonhouse/</a></p>

<p>NgoÃ i áº¥n Going trÃªn event thÃ¬ cÃ¡c báº¡n nhá»› Ä‘iá»n vÃ o form dÆ°á»›i Ä‘Ã¢y cho Ä‘áº¿n trÆ°á»›c 23:59 ngÃ y 8/4/2019. <a href="https://forms.gle/rXFu9H4i8aga3Mxi6">https://forms.gle/rXFu9H4i8aga3Mxi6</a></p>

<p>Náº¿u sá»‘ ngÆ°á»i Ä‘iá»n form Ä‘Äƒng kÃ½ nhiá»u hÆ¡n sá»©c chá»©a cá»§a há»™i trÆ°á»ng, ban tá»• chá»©c sáº½ Ã¡p dá»¥ng hÃ¬nh thá»©c Lottery nhÆ° Ä‘Ã£ thÃ´ng bÃ¡o trÃªn Facebook group trong link dÆ°á»›i Ä‘Ã¢y: <a href="https://www.facebook.com/groups/1332064783547219/permalink/1961572643929760/">https://www.facebook.com/groups/1332064783547219/permalink/1961572643929760/</a></p>

<p>Abstract cá»§a hai bÃ i nÃ³i cá»§a Dr. Tráº§n PhÆ°á»›c Duy vÃ  Tráº§n Quang Thiá»‡n:</p>

<p>=============================</p>

<p>Dr. Tran Phuoc Duy
School of Life Sciences and Technology, Tokyo Institute of Technology
Title: Machine learning aided biomolecular design: from understanding functions to virtual screening
Abstract:
The time scale of biological process, which involves upper thousands of molecules, are usually larger than microsecond exceeding the capability of the current computational approach to yield a reliable insight massively. Machine learning plays the roll as a powerful tool to help the current computational methods overcome not only the time-scale obstacle, but also help to determine the design problem for a given function in need. Here we will present and discuss about three main research themes that we are focused on: taking advantage of Markov state modeling for functional understanding of biomolecular complexes; Monte Carlo tree search as a powerful tool for enhanced sampling; actor-critic functional design of antimicrobial and antifreeze peptides.</p>

<p>=============================</p>

<p>Tráº§n Quang Thiá»‡n
Department of Computer Science, University of Tsukuba (Master&rsquo;s student)
Title: Deep learning in healthcare: Opportunities and challenges with electronic health records (EHR) data.
Abstract:
Interested in deep learning for healthcare has grown strongly recent years besides with the successes in other domains such as Computer Vision, Natural Language Processing, Speech Recognition and so forth. This talk will try to give a brief look into the recent effort of research in deep learning for healthcare. Especially, this talk focuses on the opportunities and challenges in using electronic health records (EHR) data, which is one of the most important data sources in healthcare domain.</p>
</div>
    
    <div class="col-12 col-md-6 mb-2 ">

<p>ğŸ•’ Thá»i gian: 14h~18h Chá»§ nháº­t - 27/01/2019
(má»Ÿ cá»­a Ä‘Ã³n khÃ¡ch 13h40 ~ 13h55)
ğŸ‘‰ Form Ä‘Äƒng kÃ½ tham dá»±: <a href="https://goo.gl/forms/d24f5mfbbzIzFYpE3">https://goo.gl/forms/d24f5mfbbzIzFYpE3</a>
(Háº¡n cuá»‘i Ä‘Äƒng kÃ½ lÃ  23:59 thá»© ba - 22/1/2019)</p>

<p>Xin gá»­i Ä‘áº¿n cáº£ nhÃ  VJAI lá»i chÃ o Ä‘áº§u nÄƒm! Äáº¿n vá»›i meetup má»Ÿ Ä‘áº§u cho nÄƒm 2019, chÃºng ta sáº½ cÃ¹ng nghe 2 bÃ i nÃ³i. BÃ i thá»© nháº¥t sáº½ cung cáº¥p cÃ¡i nhÃ¬n tá»•ng quÃ¡t vá» cÃ¡c mÃ´ hÃ¬nh xá»­ lÃ½ ngÃ´n ngá»¯ Ä‘Æ°á»£c Ä‘á» xuáº¥t trong nÄƒm 2018 dá»±a trÃªn ká»¹ thuáº­t Deep Learning. CÃ³ thá»ƒ nÃ³i Ä‘Ã¢y lÃ  1 xu hÆ°á»›ng má»›i trong lÄ©nh vá»±c xá»­ lÃ½ ngÃ´n ngá»¯, Ä‘ang thu hÃºt sá»± quan tÃ¢m cá»™ng Ä‘á»“ng nghiÃªn cá»©u. BÃ i thá»© hai sáº½ giá»›i thiá»‡u kiáº¿n thá»©c cÄƒn báº£n vá» máº¡ng nÆ¡ ron cÃ¹ng vá»›i thuáº­t toÃ¡n Ä‘á»ƒ huáº¥n luyá»‡n máº¡ng, thÃ nh tá»‘ cÄƒn báº£n cá»§a cÃ´ng nghá»‡ Deep Learning.</p>

<p>Ná»™i dung cá»§a buá»•i meetup láº§n nÃ y sáº½ phÃ¹ há»£p cho cáº£ nhá»¯ng chuyÃªn gia xá»­ lÃ½ ngÃ´n ngá»¯, chuyÃªn gia AI láº«n nhá»¯ng báº¡n má»›i tiáº¿p cáº­n vá»›i AI, mÃ  Ä‘áº·c biá»‡t lÃ  Deep Learnning.</p>

<p>HÃ£y cÃ¹ng Ä‘áº¿n nghe vÃ  xem cÃ¡c tÃ¡c giáº£ giá»›i thiá»‡u nhá»¯ng ká»¹ thuáº­t liÃªn quan Ä‘áº¿n cÃ¡c chá»§ Ä‘á» háº¥p dáº«n trong AI nhÃ©.</p>

<p>ğŸ¢ Äá»‹a Ä‘iá»ƒm: Cookpad Inc ã€’150-6012 æ±äº¬éƒ½æ¸‹è°·åŒºæµæ¯”å¯¿4-20-3ã€€
æµæ¯”å¯¿ã‚¬ãƒ¼ãƒ‡ãƒ³ãƒ—ãƒ¬ã‚¤ã‚¹ã‚¿ãƒ¯ãƒ¼12F
â„¹ï¸ HÆ°á»›ng dáº«n: tá»« ga JR Ebisu Ä‘i theo Ä‘Æ°á»ng Skywalk Ä‘áº¿n Ebisu Garden Place Tower, lÃªn táº§ng 12 sáº½ tháº¥y ngay vÄƒn phÃ²ng cá»§a Cookpad
<a href="https://info.cookpad.com/corporate/access">https://info.cookpad.com/corporate/access</a></p>

<p>ğŸ—£ NgÃ´n ngá»¯ nÃ³i: Tiáº¿ng Viá»‡t
ğŸ“™ NgÃ´n ngá»¯ viáº¿t trÃªn tÃ i liá»‡u: Tiáº¿ng Viá»‡t hoáº·c tiáº¿ng Anh</p>

<p>Nhá»¯ng báº¡n khÃ´ng Ä‘Äƒng kÃ½ qua form sáº½ khÃ´ng thá»ƒ vÃ o nÃªn cÃ¡c báº¡n chÃº Ã½ ngoÃ i áº¥n Going trÃªn event thÃ¬ nhá»› Ä‘iá»n vÃ o form dÆ°á»›i Ä‘Ã¢y cho Ä‘áº¿n trÆ°á»›c 23:59 thá»© ba 22/1/2019.
<a href="https://goo.gl/forms/d24f5mfbbzIzFYpE3">https://goo.gl/forms/d24f5mfbbzIzFYpE3</a></p>

<p>VÃ¬ sá»©c chá»©a cá»§a há»™i trÆ°á»ng cÃ³ háº¡n, náº¿u sá»‘ ngÆ°á»i Ä‘iá»n form Ä‘Äƒng kÃ½ nhiá»u hÆ¡n sá»©c chá»©a cá»§a há»™i trÆ°á»ng, ban tá»• chá»©c sáº½ Ã¡p dá»¥ng hÃ¬nh thá»©c Lottery nhÆ° Ä‘Ã£ thÃ´ng bÃ¡o trÃªn Facebook group trong link dÆ°á»›i Ä‘Ã¢y:
<a href="https://www.facebook.com/groups/1332064783547219/permalink/1961572643929760/">https://www.facebook.com/groups/1332064783547219/permalink/1961572643929760/</a></p>

<p>Háº¹n gáº·p láº¡i cáº£ nhÃ  vÃ o buá»•i tá»›i!</p>

<h1 id="ná»™i-dung-chÆ°Æ¡ng-trÃ¬nh">Ná»™i dung chÆ°Æ¡ng trÃ¬nh:</h1>

<p>Nguyá»…n VÅ© Thanh TÃ¹ng
LINE Corporation</p>

<p>Title: Overview of 2018 language models</p>

<p>Abstract: There was an impressive emergence of multiple competitive language models in 2018: ELMo, ULMFit, OpenAI Transformer, and BERT. There are articles on the internet explaining the internals of each model. We will try to bring a different perspective by putting all models side by side, making comparision and going to detailed, practical aspects when necessary.</p>

<p>=============================
LÃª Tuáº¥n Anh
GreenSnap, Inc.</p>

<p>Title: Neural Networks, Forward computation and Backpropagation.</p>

<p>Abstract: Giá»›i thiá»‡u vá» máº¡ng Neural Network cho ngÆ°á»i má»›i báº¯t Ä‘áº§u. Layout:</p>

<p>Nháº¯c kiáº¿n thá»©c vá» Ä‘áº¡o hÃ m, Ä‘áº¡o hÃ m tá»«ng pháº§n, chain-rule
Fully Connected Neural Network, Multi-Layer Neural Network
Feed-forward Computation,Backpropagation</p>
</div>
    
    <div class="col-12 col-md-6 mb-2 "><p>Benkyokai Ä‘áº§u tiÃªn cho 1 chuá»—i sá»± kiá»‡n trÃªn thá»m chuáº©n bá»‹ cho VWDL 2018.
Ä‘á»‹a Ä‘iá»ƒm: ã‚¢ã‚«ãƒ‡ãƒŸãƒ¼å‘ãƒ¶ä¸˜ã€€phÃ²ng Ä‘a má»¥c Ä‘Ã­ch, táº§ng 3.
<a href="https://goo.gl/maps/dErarXKPvhH2">https://goo.gl/maps/dErarXKPvhH2</a></p>

<p>ThÃ¡ng 5 nÃ y chÃºng ta hÃ¢n háº¡nh Ä‘Æ°á»£c nghe phÃ¡t biá»ƒu tá»« anh Nguyá»…n Duy KhÆ°Æ¡ng vÃ  anh Äinh Quang Huy vá»›i ná»™i dung nhÆ° sau:</p>

<p>Nguyá»…n Duy KhÆ°Æ¡ng: Deep Learning for Sparse Big Data in Recommendation Systems</p>

<p>Há»c sÃ¢u lÃ  má»™t phÆ°Æ¡ng phÃ¡p máº¡nh trong há»c mÃ¡y vÃ  cÃ³ ráº¥t nhiá»u á»©ng dá»¥ng Ä‘a dáº¡ng trong cÃ´ng nghiá»‡p, Ä‘áº·c biá»‡t trong nháº­n dáº¡ng tiáº¿ng nÃ³i vÃ  áº£nh vá»›i Ä‘á»™ chÃ­nh xÃ¡c ráº¥t cao. Äá»‘i vá»›i nhá»¯ng dá»¯ liá»‡u lá»›n vá»›i sá»‘ chiá»u lá»›n vÃ  thÆ° thÃ¬ Ä‘ang Ä‘Æ°á»£c nghiÃªn cá»©u, vÃ  báº¯t Ä‘áº§u cÃ³ nhá»¯ng káº¿t quáº£ Ä‘Ã¡ng quan tÃ¢m. BÃ i nÃ³i nÃ y sáº½ bÃ n vá» viá»‡c Ã¡p dá»¥ng há»c sÃ¢u cho cÃ¡c bÃ i toÃ¡n há»‡ thá»‘ng khuyáº¿n nghá»‹ (recommendation systems) vá»›i dá»¯ liá»‡u lá»›n vÃ  thÆ°a.</p>

<p>Äinh Quang Huy: &ldquo;XÃ¢y dá»±ng AI startup&rdquo;</p>

<p>BÃ i nÃ³i chuyá»‡n sáº½ táº­p trung vÃ o cÃ¡c váº¥n Ä‘á» xung quanh viá»‡c xÃ¢y dá»±ng AI startup: nhu cáº§u, cÆ¡ há»™i, cÃ¡c yáº¿u tá»‘ quan trá»ng nhÆ° Ã½ tÆ°á»Ÿng, dá»¯ liá»‡u, con ngÆ°á»i. BÃ i nÃ³i chuyá»‡n cÅ©ng sáº½ Ä‘i sÃ¢u hÆ¡n vá» yáº¿u tá»‘ con ngÆ°á»i: lÃ m sao Ä‘á»ƒ trá»Ÿ thÃ nh key trong má»™t AI startup.</p>

<p>Má»i ngÆ°á»i hÃ£y nhanh tay click vÃ o pháº§n join event Ä‘á»ƒ ban tá»• chá»©c náº¯m Ä‘Æ°á»£c sá»‘ ngÆ°á»i Ä‘á»ƒ chuáº©n bá»‹ nÆ°á»›c dc chu Ä‘Ã¡o hÆ¡n. Má»i ng cÃ³ thá»ƒ invite báº¡n bÃ¨ vao group Ä‘á»ƒ join sá»± kiá»‡n nhÃ©.
Háº¹n gáº·p má»i ngÆ°á»i á»Ÿ sá»± kiá»‡n.</p>

<p>P/s: má»i Ä‘Ã³ng gÃ³p, Ã½ kiáº¿n vÃ  cÃ¢u há»i cá»© thoáº£i mÃ¡i post lÃªn sá»± kiá»‡n áº¡</p>
</div>
    
    <div class="col-12 col-md-6 mb-2 ">

<p>ChÃ o cáº£ nhÃ ,</p>

<p>ThÃ¡ng 10 nÃ y chÃºng ta sáº½ Ä‘áº¿n vá»›i 1 chá»§ Ä‘á» Ä‘ang ráº¥t HOT trong 2 nÄƒm nay vá»›i sá»± xÆ°ng bÃ¡ cá»§a AlphaGo trong lÃ ng ká»³ thá»§ GO: Reinforcement Learning.
Váº­y Reinforcement Learning (Deep Reinforcement Learning) lÃ  gÃ¬ vÃ  nÃ³ cÃ³ thá»ƒ giáº£i quyáº¿t nhá»¯ng bÃ i toÃ¡n nÃ o? HÃ£y cÃ¹ng 2 diá»…n giáº£ lÃ  Nguyá»…n Duy KhÆ°Æ¡ng vÃ  Phong Nguyá»…n
cÃ¹ng tÃ¬m hiá»ƒu vá» lÄ©nh vá»±c nÃ y vÃ  1 á»©ng dá»¥ng thiáº¿t thá»±c cá»§a nÃ³ trong Recommendation System.</p>

<ul>
<li>Thá»i gian: 14h-18h chá»§ nháº­t 14/10/2018 (má»Ÿ cá»­a Ä‘Ã³n khÃ¡ch tá»« 13:30-13:55)</li>

<li><p>Äá»‹a Ä‘iá»ƒm: Cookpad Inc
ã€’150-6012 æ±äº¬éƒ½æ¸‹è°·åŒºæµæ¯”å¯¿4-20-3ã€€æµæ¯”å¯¿ã‚¬ãƒ¼ãƒ‡ãƒ³ãƒ—ãƒ¬ã‚¤ã‚¹ã‚¿ãƒ¯ãƒ¼12F
HÆ°á»›ng dáº«n: tá»« ga JR Ebisu Ä‘i theo Ä‘Æ°á»ng Skywalk Ä‘áº¿n Ebisu Garden Place Tower, lÃªn táº§ng 12 sáº½ tháº¥y ngay vÄƒn phÃ²ng cá»§a Cookpad</p></li>

<li><p>Language: Vietnamese (cÃ¡c speakers sáº½ nÃ³i báº±ng tiáº¿ng Viá»‡t)</p></li>
</ul>

<p>VÃ¬ Ä‘iá»u kiá»‡n cá»§a há»™i trÆ°á»ng chá»‰ cÃ³ 30 chá»— nÃªn cÃ¡c báº¡n tham gia xin Ä‘iá»n vÃ o form dÆ°á»›i Ä‘Ã¢y cho Ä‘áº¿n trÆ°á»›c 23:59 thá»© 4 10/10/2018
Nhá»¯ng báº¡n khÃ´ng Ä‘Äƒng kÃ½ qua form sáº½ khÃ´ng thá»ƒ vÃ o nÃªn cÃ¡c báº¡n chÃº Ã½ ngoÃ i áº¥n Going trÃªn event thÃ¬ nhá»› Ä‘iá»n vÃ o form.</p>

<p><a href="https://goo.gl/forms/8Z0mz8qW9sSCgtlK2">https://goo.gl/forms/8Z0mz8qW9sSCgtlK2</a></p>

<p>Háº¹n gáº·p láº¡i cáº£ nhÃ  vÃ o buá»•i tá»›i.</p>

<h2 id="agenda">&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;Agenda&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&ndash;</h2>

<p>Speaker: Phong Nguyá»…n (Hitachi)</p>

<p>Description:
Reinforcement learning algorithm has a long history, but recently has been piqued interests by many researchers due to the success of introducing deep neural network as an approximator of Q-values. The marriage of Deep Learning and Reinforcement Learning does not only ease the conventional â€œcurse of dimensionalityâ€ problem in RL, but also enables the action space to be extended into a continuous domain.</p>

<p>The weakness of Deep RL is the need to consume a large quantity of data to devise an optimal policy, making RL strive brightly in the domain of digital game, where endless data can be generated in the environment. Atari games and the game of Go were conquered by Google DeepMind, and recently Dota 2 were also taken by Open AI Five. But is there a way to make Deep RL adapt into a more realistic problem?</p>

<p>Letâ€™s come and have a sharing knowledge about Deep Reinforcement Learning and its future with Phong, an AI researcher from Hitachi. Phongâ€™s been trying to apply Deep RL into several problem in the industry. He will share a basic framework of Deep Reinforcement Learning and his opinions on this potential algorithm.</p>

<hr />

<p>Speaker: Nguyá»…n Duy KhÆ°Æ¡ng (Rakuten)
Title: Deep Reinforcement Learning for Recommendation Systems</p>

<p>Description:
Recommender systems are crucial in ecommerce applications to suggest items or services based on user interests.</p>

<p>The  traditional recommender systems consider the ecommendation procedure as a static process to follow a fixed strategy in order to recommend items for users.These approaches have limitations such as that they don&rsquo;t often utilize the meta data and the data of user interactions.</p>

<p>Hence, the modern approaches based on deep models and  deep reinforcement learning can take the advantages of big complicated data (text, images, userâ€™s feedbacks, etc) to optimize the recommendation strategies, which have been achieving the highly competitive results.</p>

<p>In this talk, we will summarize and discuss the state-of-the-art works and the challenges in recommendation systems based on deep reinforcement learning.</p>
</div>
    
    <div class="col-12 col-md-6 mb-2 ">

<p>Äáº¿n vá»›i Meetup #11, chÃºng ta sáº½ Ä‘Æ°á»£c gáº·p gá»¡ 2 khÃ¡ch má»i mang Ä‘áº¿n cho chÃºng ta 2 bÃ i nÃ³i trong lÄ©nh vá»±c Reinforcement Learning vÃ  Computer Vision.</p>

<ul>
<li>Thá»i gian: 14h~18h thá»© 7 - 3/11/2018 (má»Ÿ cá»­a Ä‘Ã³n khÃ¡ch 13h40 ~ 13h55)</li>
<li>Äá»‹a Ä‘iá»ƒm: Roppongi Mori Tower
ã€’106-6126 æ±äº¬éƒ½, æ¸¯åŒº, å…­æœ¬æœ¨, 6-10-1 å…­æœ¬æœ¨ãƒ’ãƒ«ã‚ºæ£®ã‚¿ãƒ¯ãƒ¼</li>
</ul>

<p>HÆ°á»›ng dáº«n: Táº­p trung táº¡i táº§ng 1 tÃ²a nhÃ  Mori Tower rá»“i cÃ¹ng checkin vÃ  lÃªn vÄƒn phÃ²ng</p>

<p>ChÃº Ã½ vÃ¬ váº¥n Ä‘á» an ninh cá»§a toÃ  nhÃ  lÃ  yÃªu cáº§u Ä‘Äƒng kÃ½ trÆ°á»›c thÃ´ng tin há» tÃªn vÃ  email nÃªn báº¡n nÃ o tham gia xin vui lÃ²ng Ä‘iá»n thÃ´ng tin theo form dÆ°á»›i Ä‘Ã¢y. Háº¡n cuá»‘i Ä‘Äƒng kÃ½ lÃ  <strong>23:59 thá»© 7 - 27/10/2018</strong>.</p>

<p><a href="https://goo.gl/forms/CLYdzD9O5YNUie9V2">https://goo.gl/forms/CLYdzD9O5YNUie9V2</a></p>

<p>Láº§n nÃ y tá»• chá»©c táº¡i Mori Tower vÃ  phÃ²ng chá»‰ cÃ³ thá»ƒ chá»©a 25 ngÆ°á»i nÃªn náº¿u sá»‘ ngÆ°á»i Ä‘Äƒng kÃ½ nhiá»u hÆ¡n, ban tá»• chá»©c sáº½ Ã¡p dá»¥ng hÃ¬nh thá»©c Lottery (nhÆ° Ä‘Ã£ thÃ´ng bÃ¡o trÃªn facebook group).
Link thÃ´ng bÃ¡o trÃªn Facebook:
<a href="https://www.facebook.com/groups/1332064783547219/permalink/1961572643929760/">https://www.facebook.com/groups/1332064783547219/permalink/1961572643929760/</a></p>

<p>ThÃªm ná»¯a lÃ  viá»‡c vÃ o toÃ  nhÃ  khÃ´ng dá»… dÃ ng nÃªn hÃ´m Ä‘áº¥y Ä‘á» nghá»‹ cÃ¡c báº¡n Ä‘áº¿n Ä‘Ãºng giá».</p>

<p>Háº¹n gáº·p láº¡i cáº£ nhÃ  vÃ o buá»•i sáº¯p tá»›i!</p>

<h2 id="ná»™i-dung-chÆ°Æ¡ng-trÃ¬nh">Ná»™i dung chÆ°Æ¡ng trÃ¬nh:</h2>

<h3 id="speaker">Speaker:</h3>

<p>Nguyá»…n Tuáº¥n DÆ°Æ¡ng</p>

<h3 id="abstract">Abstract:</h3>

<p>Policy Gradients (PG) is a powerful approach for modern model-free reinforcement learning. In this talk, we discuss various PG algorithms, from the vanilla PG to actor-critic style PG to some recent state-of-the-art methods such as TRPO/PPO. Along the way, we try to understand their motivation, technical details and possible future works.
This talk by no means can cover all aspects of this vast topic, but hopefully will provide enough basic knowledge for aspiring audience to dive into latest PG research.</p>

<h3 id="references">References:</h3>

<ol>
<li>Chapter 13 from &ldquo;Reinforcement Learning, An introduction&rdquo; by prof. Richard S. Sutton
<a href="https://drive.google.com/file/d/1opPSz5AZ_kVa1uWOdOiveNiBFiEOHjkG/view">https://drive.google.com/file/d/1opPSz5AZ_kVa1uWOdOiveNiBFiEOHjkG/view</a></li>
<li>A few papers about TRPO or below blog:
<a href="https://towardsdatascience.com/introduction-to-various-reinforcement-learning-algorithms-part-ii-trpo-ppo-87f2c5919bb9">https://towardsdatascience.com/introduction-to-various-reinforcement-learning-algorithms-part-ii-trpo-ppo-87f2c5919bb9</a></li>
</ol>

<hr />

<h3 id="speaker-1">Speaker:</h3>

<p>Phan DoÃ£n PhÃºc (FPT Japan Holdings Co., Ltd.)</p>

<h3 id="title-triplet-loss-the-good-the-bad-and-the-ugly">Title: Triplet Loss â€“ the Good the Bad and the Ugly</h3>

<h3 id="abstract-1">Abstract:</h3>

<p>Triplet Loss - born in 2015 - successfully solved &ldquo;Face Recognition&rdquo; Task, a classical problem in Computer Vision that used to cost a lot of researchers&rsquo; tears and sweat. Since then, there is no other big progress for this Loss and it seems to be no longer a hot topic in DNN these days
From the view-point of an engineer, I found it very useful to solve many tasks in production level. So the main point of my talk is to
(1) Introduce this method to the listeners (just some basic concepts)
(2) Let&rsquo;s go in detailed and discuss about its strength and weakness</p>

<h3 id="references-1">References:</h3>

<p><a href="https://arxiv.org/abs/1503.03832">https://arxiv.org/abs/1503.03832</a></p>
</div>
    
    <div class="col-12 col-md-6 mb-2 ">

<p>ChÃ o cáº£ nhÃ , Ä‘áº¿n vá»›i Meetup #12, chÃºng ta sáº½ Ä‘Æ°á»£c gáº·p gá»¡ khÃ¡ch má»i tá»« 2 cÃ´ng ty cÃ´ng nghá»‡ ná»•i tiáº¿ng lÃ  Microsoft vÃ  NVIDIA, vá»›i bÃ i nÃ³i vá» nhá»¯ng chá»§ Ä‘á» cá»±c hot trong AI hiá»‡n nay lÃ  chatbot vÃ  cÃ´ng nghá»‡ xe tá»± lÃ¡i.</p>

<ul>
<li>Thá»i gian: 14h~18h Chá»§ nháº­t - 02/12/2018 (má»Ÿ cá»­a Ä‘Ã³n khÃ¡ch 13h40 ~ 13h55)</li>
<li>Äá»‹a Ä‘iá»ƒm: Microsoft Japan office táº§ng 30 <br>
108-0075 æ±äº¬éƒ½æ¸¯åŒºæ¸¯å— 2-16-3 å“å·ã‚°ãƒ©ãƒ³ãƒ‰ã‚»ãƒ³ãƒˆãƒ©ãƒ«ã‚¿ãƒ¯ãƒ¼ <br>
<a href="https://www.microsoft.com/ja-jp/mscorp/branch/sgt.aspx">https://www.microsoft.com/ja-jp/mscorp/branch/sgt.aspx</a></li>
</ul>

<p>HÆ°á»›ng dáº«n: tá»« ga JR Shinagawa cá»­a Kounan (æ¸¯å—å£) Ä‘i theo skywalker lÃ  Ä‘áº¿n chá»— reception (táº§ng 2). Táº¡i Ä‘Ã¢y báº¡n sáº½ láº¥y vÃ© vÃ o vÃ  lÃªn táº§ng 30.</p>

<p>ChÃº Ã½: do yÃªu cáº§u an ninh toÃ  nhÃ , Ä‘á» nghá»‹ cÃ¡c báº¡n Ä‘iá»n thÃ´ng tin theo form dÆ°á»›i Ä‘Ã¢y. Háº¡n cuá»‘i Ä‘Äƒng kÃ½ lÃ  <strong>23:59 thá»© 3 - 27/11/2018</strong>.</p>

<p><a href="https://goo.gl/forms/u5d9lExohdU0Czpv2">https://goo.gl/forms/u5d9lExohdU0Czpv2</a></p>

<p>Ai khÃ´ng ká»‹p Ä‘Äƒng kÃ½ trÆ°á»›c thá»i háº¡n trÃªn sáº½ khÃ´ng Ä‘Æ°á»£c vÃ o toÃ  nhÃ  nÃªn ngoÃ i áº¥n Going thÃ¬ cÃ¡c báº¡n <strong>nhá»› Ä‘iá»n vÃ o form</strong> trÃªn nhÃ©.</p>

<p>Láº§n nÃ y ban tá»• chá»©c Ä‘Ã£ sáº¯p xáº¿p phÃ²ng rá»™ng hÆ¡n nhÆ°ng cÅ©ng chá»‰ chá»©a Ä‘Æ°á»£c 50 ngÆ°á»i nÃªn náº¿u sá»‘ ngÆ°á»i Ä‘Äƒng kÃ½ nhiá»u hÆ¡n, ban tá»• chá»©c sáº½ Ã¡p dá»¥ng hÃ¬nh thá»©c Lottery (nhÆ° Ä‘Ã£ thÃ´ng bÃ¡o trÃªn facebook group). Káº¿t quáº£ Lottery sáº½ Ä‘Æ°á»£c thÃ´ng bÃ¡o vÃ o thá»© 4 - 28/11/2018.
ThÃªm ná»¯a lÃ  viá»‡c vÃ o toÃ  nhÃ  khÃ´ng dá»… dÃ ng nÃªn cÃ¡c báº¡n tÃ­nh toÃ¡n thá»i gian cáº©n tháº­n Ä‘á»ƒ Ä‘áº¿n Ä‘Ãºng giá» nhÃ©.</p>

<p>Háº¹n gáº·p láº¡i cáº£ nhÃ  vÃ o buá»•i sáº¯p tá»›i!</p>

<h2 id="ná»™i-dung-chÆ°Æ¡ng-trÃ¬nh">Ná»™i dung chÆ°Æ¡ng trÃ¬nh:</h2>

<h2 id="lÃª-trung-kiÃªn">LÃª Trung KiÃªn</h2>

<p>AI Software Engineer, Microsoft Japan</p>

<h3 id="rinna">Rinna</h3>

<p>Rinna lÃ  1 chatbot láº§n Ä‘áº§u Ä‘Æ°á»£c ra máº¯t cÃ´ng chÃºng trÃªn ná»n táº£ng nháº¯n tin LINE tá»« nÄƒm 2015. Ká»ƒ tá»« Ä‘Ã³, Rinna Ä‘Ã£ Ä‘Æ°á»£c phÃ¡t triá»ƒn vÃ  trá»Ÿ thÃ nh 1 trong nhá»¯ng &ldquo;conversational AI&rdquo; ná»•i tiáº¿ng nháº¥t á»Ÿ Nháº­t.
Pháº§n Ä‘áº§u cá»§a bÃ i nÃ³i chuyá»‡n láº§n nÃ y sáº½ Ä‘Æ°á»£c giÃ nh cho viá»‡c giá»›i thiá»‡u lá»‹ch sá»­ cÅ©ng nhÆ° tÆ°Æ¡ng lai cá»§a dá»± Ã¡n.
Sau khi Ä‘iá»ƒm qua nhá»¯ng Ä‘iá»ƒm quan trá»ng trong dá»± Ã¡n nÃ y, pháº§n tiáº¿p theo sáº½ trÃ¬nh bÃ y chi tiáº¿t vá» dá»± Ã¡n Gá»i Ä‘iá»‡n thoáº¡i (Phone Call) vá»›i Rinna: tá»« viá»‡c thiáº¿t káº¿ tá»•ng tháº¿ cho tá»›i triá»ƒn khai chi tiáº¿t.
Pháº§n cuá»‘i cÃ¹ng sáº½ lÃ  nhá»¯ng chia sáº» vá» kinh nghiá»‡m phÃ¡t triá»ƒn 1 sáº£n pháº©m AI tá»« Ä‘áº§u tá»›i cuá»‘i.</p>

<h2 id="tham-kháº£o-thÃªm-vá»-rinna-https-www-rinna-jp">Tham kháº£o thÃªm vá» Rinna: <a href="https://www.rinna.jp/">https://www.rinna.jp/</a></h2>

<h2 id="vÃµ-Ä‘á»©c-khÃ¡nh">VÃµ Äá»©c KhÃ¡nh</h2>

<p>Deep Learning Solution Architect for Robotics &amp; Autonomous Machines, NVIDIA</p>

<h3 id="cÃ´ng-nghá»‡-xe-tá»±-lÃ¡i-cá»§a-nvidia-quÃ¡-khá»©-hiá»‡n-táº¡i-tÆ°Æ¡ng-lai">CÃ´ng nghá»‡ xe tá»± lÃ¡i cá»§a NVIDIA - QuÃ¡ khá»©, Hiá»‡n táº¡i, TÆ°Æ¡ng lai</h3>

<p>Pháº§n Ä‘áº§u cá»§a bÃ i nÃ³i chuyá»‡n sáº½ Ä‘Æ°á»£c giÃ nh cho viá»‡c trÃ¬nh bÃ y vá» quÃ¡ trÃ¬nh hÃ¬nh thÃ nh nhÃ³m xe hÆ¡i tá»± Ä‘á»™ng cá»§a cÃ´ng ty tá»« 2008 Ä‘áº¿n 2014, cÃ¡c sáº£n pháº©m káº¿t quáº£ cá»§a giai Ä‘oáº¡n Ä‘Ã³ mÃ  chÃºng ta cÃ³ thá»ƒ táº¡m xem lÃ  thá»i quÃ¡ khá»©.
Pháº§n káº¿ tiáº¿p cá»§a bÃ i nÃ³i sáº½ giÃ nh pháº§n lá»›n thá»i gian Ä‘á»ƒ giá»›i thiá»‡u vá» thá»i hiá»‡n táº¡i, Ä‘Æ°á»£c xem lÃ  tá»« 2014 Ä‘áº¿n nay, vá»›i ná»™i dung trÃ¬nh bÃ y vá» cÆ¡ sá»Ÿ háº¡ táº§ng pháº§n cá»©ng vÃ  pháº§n má»m cho xe tá»± lÃ¡i, bao gá»“m chuáº©n bá»‹ dá»¯ liá»‡u huáº¥n luyá»‡n, cÃ¡c mÃ´ hÃ¬nh AI Ä‘Ã£ vÃ  Ä‘ang Ä‘Æ°á»£c sá»­ dá»¥ng, há»‡ thá»‘ng mÃ´ phá»ng lÃ¡i tá»± Ä‘á»™ng, cÅ©ng nhÆ° cÃ¡c káº¿t quáº£ Ä‘Ã£ Ä‘áº¡t Ä‘Æ°á»£c.
Pháº§n cuá»‘i cá»§a bÃ i nÃ³i sáº½ cá»‘ gáº¯ng cung cáº¥p thÃ´ng tin vá» cÃ¡c dá»± Ã¡n Ä‘ang thá»±c hiá»‡n nháº±m hÆ°á»›ng Ä‘áº¿n xe tá»± lÃ¡i má»©c 5 trong vÃ²ng 5 nÄƒm káº¿ tiáº¿p.</p>
</div>
    
    <div class="col-12 col-md-6 mb-2 ">

<p>ChÃ o cáº£ nhÃ , Ä‘áº¿n vá»›i buá»•i Meetup cuá»‘i cÃ¹ng cá»§a nÄƒm 2018, chÃºng ta sáº½ Ä‘áº¿n vá»›i 2 bÃ i toÃ¡n ná»•i trá»™i trong lÄ©nh vá»±c xá»­ lÃ½ ngÃ´n ngá»¯ tá»± nhiÃªn lÃ  dá»‹ch mÃ¡y (Machine Translattion) vÃ  Ä‘á»c hiá»ƒu vÄƒn báº£n (Reading Comprehension). HÃ£y cÃ¹ng Ä‘áº¿n xem mÃ¡y tÃ­nh Ä‘ang tiáº¿n sÃ¡t vá»›i con ngÆ°á»i trong viá»‡c xá»­ lÃ½ ngÃ´n ngá»¯ Ä‘áº¿n Ä‘Ã¢u nhÃ©.</p>

<p>Thá»i gian: 14h~18h Chá»§ nháº­t - 16/12/2018 (má»Ÿ cá»­a Ä‘Ã³n khÃ¡ch 13h40 ~ 13h55)
Äá»‹a Ä‘iá»ƒm: BizReach, Inc. æ¸‹è°·363æ¸…æ°´ãƒ“ãƒ«
ã€’150-0002, 3 Chome-6-3 Shibuya, Tokyo
<a href="https://goo.gl/maps/VbbahJ1x9152">https://goo.gl/maps/VbbahJ1x9152</a>
Háº¡n cuá»‘i Ä‘Äƒng kÃ½ lÃ  23:59 thá»© 3 - 11/12/2018.</p>

<p><a href="https://goo.gl/forms/pjMCFs7gDayq7sW93">https://goo.gl/forms/pjMCFs7gDayq7sW93</a></p>

<p>Ai khÃ´ng ká»‹p Ä‘Äƒng kÃ½ trÆ°á»›c thá»i háº¡n trÃªn sáº½ khÃ´ng Ä‘Æ°á»£c vÃ o toÃ  nhÃ  nÃªn ngoÃ i áº¥n Going thÃ¬ cÃ¡c báº¡n nhá»› Ä‘iá»n vÃ o form trÃªn nhÃ©.</p>

<p>Láº§n nÃ y ban tá»• chá»©c Ä‘Ã£ sáº¯p xáº¿p phÃ²ng rá»™ng hÆ¡n nhÆ°ng cÅ©ng chá»‰ chá»©a Ä‘Æ°á»£c 50 ngÆ°á»i nÃªn náº¿u sá»‘ ngÆ°á»i Ä‘Äƒng kÃ½ nhiá»u hÆ¡n, ban tá»• chá»©c sáº½ Ã¡p dá»¥ng hÃ¬nh thá»©c Lottery (nhÆ° Ä‘Ã£ thÃ´ng bÃ¡o trÃªn facebook group). ThÃªm ná»¯a lÃ  viá»‡c vÃ o toÃ  nhÃ  khÃ´ng dá»… dÃ ng nÃªn cÃ¡c báº¡n tÃ­nh toÃ¡n thá»i gian cáº©n tháº­n Ä‘á»ƒ Ä‘áº¿n Ä‘Ãºng giá» nhÃ©.</p>

<p>Háº¹n gáº·p láº¡i cáº£ nhÃ  vÃ o buá»•i sáº¯p tá»›i!</p>

<h1 id="ná»™i-dung-chÆ°Æ¡ng-trÃ¬nh">Ná»™i dung chÆ°Æ¡ng trÃ¬nh:</h1>

<p>Pháº¡m Quang Khang
AI Solutions Architect</p>

<p>Title: Pay More Attention to Attention Mechanism</p>

<p>Since proposed in 2014, Attention has been recently evolved and become one of the most attended mechanism in fields like computer vision, nature language processing and even in recommendation system. Taking machine translation problem as an example, this talk will walk through the intuition of this mechanism as well as its evolution from encode-decoder attention to self-attention and lastly, Transformer (Attention is all you need: rank 4th most popular paper of all time on Arxiv Sanity), which removed completely conventional RNNs architecture.</p>

<p>References
1. Bahdanau et al,. Neural Machine Translation by Jointly Learning to Align and Translate. ICLR 2015
2. Thang Luong et al,. Effective Approaches to Attention-based Neural Machine Translation. EMNLP 2015.
3. Lin et al,. A Structured Self-attentive Sentence Embedding. ICLR 2017.
4. Vaswani et al,. Attention Is All You Need. NIPS 2017.</p>

<p>=============================
Nguyá»…n PhÆ°á»›c Táº¥t Äáº¡t
AI Research Engineer (BizReach, Inc.)</p>

<p>Pháº¡m Quang Khang
AI Solutions Architect</p>

<p>Title: Machine Can Do Reading Comprehension Test for You</p>

<p>1Reading comprehension, or question answering, is one of the most important and challenging natural language processing (NLP) tasks, in which a concrete answer is produced with respect to a question on an input text. This task is hard for even human when the input texts are complex, and it is used to test language proficiency of readers.</p>

<p>With the advancement of Deep Learning (DL) in many domains, NLP researchers are seeking for various ways to apply DL techniques to NLP tasks, including reading comprehension task. In this trend, a robust deep neural network architecture is designed to capture hierarchical representations of language, which then maps a question and a context as inputs directly to the appropriate answer as output.</p>

<p>In this talk, we will explore some neural network architectures for reading comprehension task which give state-of-the-art results even better than human performance. At the end of the talk, let&rsquo;s give machine an input text, then you ask, it answers.</p>

<p>References:
1. J. Devlin, M.-W. Chang, K. Lee, and K. Toutanova,. &ldquo;Bert: Pre-training of deep bidirectional transformers for language understanding,&rdquo; arXiv preprint arXiv:1810.04805, 2018.
2. A. W. Yu, D. Dohan, M.-T. Luong, R. Zhao, K. Chen, M. Norouzi, and Q. V. Le,. Qanet: Combining local convolution with global self-attention for reading comprehension. ICLR 2018.
3. Pranav Rajpurkar, Jian Zhang, Konstantin Lopyrev, and Percy Liang,. Squad: 100,000+ questions for machine comprehension of text. EMNLP 2016.</p>
</div>
    
    <div class="col-12 col-md-6 mb-2 "><p>CÃ¹ng tÃ¬m hiá»ƒu cÃ¡c thuáº­t toÃ¡n Ä‘Ã£ Ä‘Æ°á»£c phÃ¡t triá»ƒn trong bÃ i toÃ¡n tá»‘i Æ°u hÃ³a Gradient descent
Benkyokai thÃ¡ng 6 sáº½ Ä‘Æ°á»£c má»™t nhÃ³m cÃ¡c báº¡n trÃ¬nh bÃ y vá» chá»§ Ä‘á»ƒ Gradient Descent Optimization Algorithms
Vá»›i 1 chá»§ Ä‘á» xuyÃªn suá»‘t 2 tiáº¿ng thá»i lÆ°á»£ng cá»§a chÆ°Æ¡ng trÃ¬nh, nhÃ³m sáº½ trÃ¬nh bÃ y tá»« nhá»¯ng khÃ¡i niá»‡m cÆ¡ báº£n nhÆ° Gradient, nhá»¯ng thÃ¡ch thá»©c trong bÃ i toÃ¡n tá»‘i Æ°u hÃ³a vÃ  nhá»¯ng thuáº­t toÃ¡n Ä‘Ã£ vÃ  Ä‘ang Ä‘Æ°á»£c á»©ng dá»¥ng rá»™ng rÃ£i: Stochastic gradient descent, momentum, ADA Grad hay Adam.
NhÃ³m sáº½ cover tá»« lÃ½ thuyáº¿t cho Ä‘áº¿n code, coding vÃ  1 bÃ i test nhá».
NgÆ°á»i trÃ¬nh bÃ y: Nguyá»…n BÃ¬nh KhiÃªm, Tráº§n Duy, Khang Pham, VÄƒn PhÃº Quang Huy, Táº¡ Äá»©c TÃ¹ng
Do phÃ²ng bÃ© nÃªn sá»‘ ng tham gia bá»‹ giá»›i háº¡n lÃ  20, first come first serve</p>
</div>
    
    <div class="col-12 col-md-6 mb-2 "><p>9 Sep 2017 at 10:00 â€“ 10 Sep 2017 at 13:00</p>

<p>Thá»i gian: 10:00-13:00
Äá»‹a Ä‘iá»ƒm: æ±äº¬éƒ½æ¸‹è°·åŒºé“ç„å‚1-17-9 ãƒ´ã‚§ãƒ©ãƒã‚¤ãƒ„506å·å®¤
Äá»‹a Ä‘iá»ƒm láº§n nÃ y lÃ  á»Ÿ Shibuya, khÃ¡c vá»›i má»i láº§n nÃªn má»i ngÆ°á»i chÃº Ã½
KhÃ¡i quÃ¡t ná»™i dung:
Giá»›i thiá»‡u vá» generative modeling, má»™t bÃ i toÃ¡n trong unsupervised learning. Cá»¥ thá»ƒ chÃºng ta sáº½ tÃ¬m hiá»ƒu vá» mÃ´ hÃ¬nh GAN vÃ  má»™t hÆ°á»›ng tiáº¿p cáº­n tá»« gÃ³c nhÃ¬n distribution matching.
TÃ¡c giáº£: Nguyá»…n DÆ°Æ¡ng, Nguyá»…n Äáº¡t</p>

<p>1 Ä‘Ã´i lá»i vá» GANs(Generative Adversarial Network):
&ldquo;Generative Adversarial Network (GAN), and the variations that are now being proposed is the most interesting idea in the last 10 years in ML, in my opinion.&rdquo; Yann LeCun
Ã tÆ°á»Ÿng cá»§a GAN lÃ  sinh ra dá»¯ liá»‡u tá»•ng há»£p (artificial data) tá»« nhá»¯ng dá»¯ liá»‡u cÃ³ sáºµn vÃ  dá»¯ liá»‡u má»›i nÃ y sáº½ giá»‘ng tháº­t Ä‘áº¿n má»©c ko thá»ƒ phÃ¢n biá»‡t dc nÃ³ lÃ  hÃ ng dc táº¡o ra chá»© khÃ´ng pháº£i dá»¯ liá»‡u cÃ³ ban Ä‘áº§u.
1 vÃ­ dá»¥ ráº¥t hay Ä‘Æ°á»£c dÃ¹ng Ä‘á»ƒ nÃ³i vá» GAN lÃ  viá»‡c training cho 1 anh cáº£nh sÃ¡t chuyÃªn Ä‘i phÃ¢n biá»‡t tiá»n giáº£ tiá»n tháº­t vÃ  training cho 1 anh trá»™m chuyÃªn lÃ m tiá»n giáº£. Viá»‡c training song song cho cáº£ 2 ngÆ°á»i sáº½ Ä‘c tiáº¿n hÃ nh báº±ng cÃ¡ch trá»™m in tiá»n giáº£ ra Ä‘Æ°a cho cáº£nh xem, nháº­n láº¡i feedback lÃ  Ä‘áº¥y lÃ  giáº£ hay tháº­t. Viá»‡c cháº¡y song song sáº½ dá»«ng khi áº£nh cáº£nh sÃ¡t cá»§a chÃºng ta khÃ´ng cÃ²n phÃ¢n biá»‡t dc tháº­t vÃ  giáº£ ná»¯a, tá»« Ä‘áº¥y chÃºng ta cÃ³ mÃ¡y in tiá»n xá»‹n :D
ÄÃ¢y lÃ  link tÃ i liá»‡u gá»‘c cho cÃ¡c báº¡n muá»‘n xem ká»¹ thÃªm:
<a href="https://arxiv.org/abs/1406.2661">https://arxiv.org/abs/1406.2661</a></p>
</div>
    
    <div class="col-12 col-md-6 mb-2 "><p>Saturday, 31 March 2018 at 14:00</p>

<p>Location link: <a href="https://info.cookpad.com/corporate/access">https://info.cookpad.com/corporate/access</a>
Benkyokai thÃ¡ng 3 sáº½ cÃ³ sá»± gÃ³p máº·t cá»§a 2 diá»…n giáº£ vá»›i 2 chá»§ Ä‘á» ráº¥t hot cho practitioners:
1. VÄƒn PhÃº Quang Huy:PhÃ¢n loáº¡i Ã½ kiáº¿n Ä‘Ã³ng gÃ³p cá»§a ngÆ°á»i dÃ¹ng (customer feedback classification)
Ã kiáº¿n Ä‘Ã³ng gÃ³p cá»§a ngÆ°á»i dÃ¹ng lÃ  ráº¥t quan trá»ng trong viá»‡c phÃ¡t triá»n báº¥t cá»© dá»‹ch vá»¥ nÃ o. Tuy nhiÃªn, dá»‹ch vá»¥ cÃ³ sá»‘ lÆ°á»£ng ngÆ°á»i dÃ¹ng lá»›n vá»›i hÃ ng trÄƒm Ã½ kiáº¿n Ä‘Ã³ng gÃ³p Ä‘áº¿n má»—i ngÃ y thÃ¬ viá»‡c chuyá»ƒn táº£i tá»«ng Ã½ kiáº¿n Ä‘áº¿n Ä‘Ãºng team thÃ­ch há»£p lÃ  viá»‡c khÃ´ng há» dá»… dÃ ng. CÃ¡ch lÃ m phá»• biáº¿n nháº¥t hiá»‡n nay lÃ  cá»­ ngÆ°á»i gáº¯n tag cho má»—i Ã½ kiáº¿n, Ä‘á»ƒ rá»“i tá»« Ä‘Ã³ chuyá»ƒn Ä‘áº¿n team thÃ­ch há»£p. CÃ´ng viá»‡c nÃ y vá» cÆ¡ báº£n lÃ  láº·p Ä‘i láº·p láº¡i vÃ  tá»‘n thá»i gian. Trong bÃ i thuyáº¿t trÃ¬nh sáº¯p tá»›i, mÃ¬nh sáº½ nÃ³i vá» viá»‡c sá»­ dá»¥ng Machine Learning Ä‘á»ƒ gáº¯n tag tá»± Ä‘á»™ng, qua Ä‘Ã³ giÃºp giáº£m thá»i gian Ä‘Ã¡ng ká»ƒ so vá»›i viá»‡c lÃ m thá»§ cÃ´ng trÆ°á»›c Ä‘Ã¢y.</p>

<ol>
<li>BÃ¹i Há»“ng HÃ : Tá»« hadoop Ä‘áº¿n Data Warehouse, cÃ¡i nhÃ¬n tá»•ng quan vá» &ldquo;BigData&rdquo;
CÃ´ng nghá»‡ BigData cá»¥ thá»ƒ bao gá»“m nhá»¯ng gÃ¬? BigData Ä‘Æ°á»£c ká»³ vá»ng giáº£i quyáº¿t váº¥n Ä‘á» gÃ¬?
BÃ i nÃ³i sáº½ báº¯t Ä‘áº§u báº±ng viá»‡c giá»›i thiá»‡u tá»•ng quan hadoop vÃ  ecosystem xung quan hadoop, váº¥n Ä‘á» mÃ  hadoop giáº£i quyáº¿t trong data warehouse, vÃ  káº¿t thÃºc báº±ng má»™t vÃ i gÃ³c nhÃ¬n cÃ¡ nhÃ¢n vá» BigData</li>
</ol>
</div>
    
    <div class="col-12 col-md-6 mb-2 "><p>Diá»…n giáº£: Khang Pháº¡m
TiÃªu Ä‘á»: Word embedding
Note: tá»« thÃ¡ng nÃ y, cÃ¡c event sáº½ Ä‘á»•i tÃªn thÃ nh VN Machine Learning Meetup (láº§n nÃ y lÃ  láº§n thá»© 6 trong 1 nÄƒm qua ^^)
Xá»­ lÃ½ cÃ¡c bÃ i toÃ¡n vá» Text lÃ  1 váº¥n Ä‘á» khÃ¡ khÃ³ nhÆ°ng cÃ³ ráº¥t nhiá»u á»©ng dá»¥ng trong thá»±c tiá»…n: sentiment analytics, machine translation, chatbotâ€¦ CÃ¡i khÃ³ khi xá»­ lÃ½ text lÃ  viá»‡c text khÃ´ng pháº£i sá»‘ nhÆ° áº£nh nhÆ°ng cÃ¡c tá»« trong 1 tá»« Ä‘iá»ƒn náº¿u xá»­ lÃ½ nhÆ° 1 biáº¿n Ä‘á»™c láº­p thÃ¬ sáº½ bá» qua ráº¥t nhiá»u chi tiáº¿t vá» ngá»¯ nghÄ©a cá»§a tá»« vÃ  vÄƒn báº£n. Giáº£i quyáº¿t bÃ i toÃ¡n biáº¿n cÃ¡c tá»« trong 1 bá»™ tá»« Ä‘iá»ƒn thÃ nh nhá»¯ng dense-vector tá»« lÃ¢u Ä‘Ã£ trá»Ÿ thÃ nh bÃ i toÃ¡n cÆ¡ báº£n Ä‘áº§u tiÃªn khi xá»­ lÃ½ text vÃ  Ä‘Ã£ cÃ³ ráº¥t nhiá»u thuáº­t toÃ¡n thÃ´ng dá»¥ng nhÆ° word2vec hay fasttext (facebook). Trong bÃ i nÃ³i nÃ y mÃ¬nh sáº½ giá»›i thiá»‡u lÃ½ thuyáº¿t cÆ¡ báº£n cá»§a cÃ¡c thuáº­t toÃ¡n nÃ y</p>
</div>
    
    <div class="col-12 col-md-6 mb-2 "><p>TiÃªu Ä‘á»: RNN vÃ  mÃ´ hÃ¬nh hoÃ¡ ngÃ´n ngá»¯
Diá»…n giáº£: Äá»— Minh Háº£i
TÃ³m táº¯t:
CÃ¡c cÃ¢u tá»« trong má»™t vÄƒn báº£n khÃ´ng Ä‘Æ°á»£c sáº¯p xáº¿p má»™t cÃ¡ch ngáº«u nhiÃªn mÃ  theo trÃ¬nh tá»± vÄƒn cáº£nh ngá»¯ nghÄ©a nháº¥t Ä‘á»‹nh nÃ o Ä‘Ã³. NÃªn viá»‡c biáº¿t trÆ°á»›c ngá»¯ cáº£nh trÆ°á»›c Ä‘Ã³ cÃ³ thá»ƒ giÃºp ta hÃ¬nh dung Ä‘Æ°á»£c ngá»¯ cáº£nh cÃ³ thá»ƒ xuáº¥t hiá»‡n tiáº¿p theo. VÃ­ dá»¥, náº¿u ta cÃ³ Ä‘oáº¡n &ldquo;Äáº¹p trai thÃ¬ láº¯m&rdquo;, ta cÃ³ thá»ƒ dá»± Ä‘oÃ¡n Ä‘Æ°á»£c tá»« tiáº¿p theo cÃ³ thá»ƒ xuáº¥t hiá»‡n lÃ  &ldquo;gÃ¡i&rdquo;, &ldquo;tiá»n&rdquo;, &ldquo;trai&rdquo;â€¦ Trong bÃ i viáº¿t nÃ y, mÃ¬nh sáº½ trÃ¬nh bÃ y vá» lÃ½ thuyáº¿t cÆ¡ báº£n cá»§a máº¡ng RNN - 1 mÃ´ hÃ¬nh mÃ´ phá»ng sá»± phá»¥ thuá»™c vÄƒn cáº£nh nhÆ° váº­y. NgoÃ i ra, mÃ¬nh cÅ©ng nÃ³i thÃªm vá» biáº¿n thá»ƒ ná»•i tiáº¿ng cá»§a RNN lÃ  LSTM nháº±m nÃ¢ng cao hiá»‡u quáº£ tÃ­nh toÃ¡n cá»§a RNN.</p>

<p>Bonus: sáº½ cÃ³ 5 phÃºt tá»•ng quan vá» há»™i tháº£o JSAI 2018 vá»«a diá»…n ra á»Ÿ Kagoshima thÃ¡ng 6 vá»«a qua do 1 báº¡n Ä‘i thá»±c táº¿ vá» trÃ¬nh bÃ y.</p>
</div>
    
    <div class="col-12 col-md-6 mb-2 "><p>Sequence to Sequence Models: A Review</p>

<p>Presenter: Cao Vu Dung</p>

<p>In this seminar, we will explore several important applications of the fundamental RNN models for various critical tasks including image captioning, machine translation, and speech recognition. First, a brief review of the RNN models is presented to provide the prerequisite and essential knowledge of RNN. In the main part, we will dig deep into the major cutting-edge algorithms and techniques for the tasks of image captioning, machine translation, and speech recognition through reviewing a number of recent influential papers on sequence to sequence models that have achieved the state-of-the-art accuracy and performance.</p>

<p>Trong buá»•i seminar nÃ y, chÃºng ta sáº½ tháº£o luáº­n vá» sequence to sequence models qua á»©ng dá»¥ng cá»¥ thá»ƒ cá»§a cÃ¡c mÃ´ hÃ¬nh nÃ y.</p>

<p>ÄÃ¢y lÃ  ná»™i dung mang tÃ­nh káº¿ thá»«a tá»« hai bÃ i phÃ¡t biá»ƒu trÆ°á»›c cá»§a Khang Pham vá» Word Embedding vÃ  Hai Minh Do vá» sequence models. Má»i tham kháº£o láº¡i hai bÃ i phÃ¡t biá»ƒu nÃ y Ä‘á»ƒ láº¥y kiáº¿n thá»©c cÆ¡ báº£n vá» word embedding vÃ  Recurrent Neural Networks.</p>

<p>Äiá»ƒm khÃ¡c biá»‡t lÃ  trong buá»•i nÃ y mÃ¬nh sáº½ trÃ¬nh bÃ y cÃ¡c idea chÃ­nh tá»« papers thay vÃ¬ Ä‘i sÃ¢u vÃ o phÃ¢n tÃ­ch tá»«ng paper Ä‘á»ƒ giÃºp cÃ¡c báº¡n hÃ¬nh dung Ä‘Æ°á»£c bá»©c tranh lá»›n vá» RNN vÃ  cÃ¡c á»©ng dá»¥ng hiá»‡n nay. BÃªn cáº¡nh Ä‘Ã³ mÃ¬nh sáº½ demo thá»­ má»™t vÃ­ dá»¥ thá»±c táº¿ Ä‘Æ¡n giáº£n náº¿u thá»i gian cho phÃ©p.</p>

<p>Vá»›i cÃ¡ch lÃ m nhÆ° váº­y, cÃ¡c báº¡n dÃ¹ má»›i vá»›i deep learning (nhÆ° mÃ¬nh :D) cÅ©ng dá»… dÃ ng náº¯m báº¯t nhanh vÃ  cÃ³ thá»ƒ triá»ƒn khai ngay vÃ o má»™t dá»± Ã¡n thá»±c táº¿.</p>

<p>Key references:</p>

<p>Sutskever, I., Vinyals, O., &amp; Le, Q. V. (2014). Sequence to sequence learning with neural networks. In Advances in neural information processing systems (pp. 3104-3112).</p>

<p>Cho, K., Van MerriÃ«nboer, B., Gulcehre, C., Bahdanau, D., Bougares, F., Schwenk, H., &amp; Bengio, Y. (2014). Learning phrase representations using RNN encoder-decoder for statistical machine translation. arXiv preprint arXiv:1406.1078.</p>

<p>Bahdanau, D., Cho, K., &amp; Bengio, Y. (2014). Neural machine translation by jointly learning to align and translate. arXiv preprint arXiv:1409.0473.</p>
</div>
    
    <div class="col-12 col-md-6 mb-2 ">

<p>ChÃ o cáº£ nhÃ ,</p>

<p>Meetup thÃ¡ng 9 láº§n nÃ y sáº½ lÃ  2 bÃ i nÃ³i vá» Mask-RCNN vÃ  Hidden Markov Model. Trong khi Mask-RCNN lÃ  thuáº­t toÃ¡n gáº§n Ä‘Ã¢y do Facebook AI Research phÃ¡t triá»ƒn Ä‘á»ƒ giáº£i quyáº¿t bÃ i toÃ¡n Instance Segmentation trong Computer Vision thÃ¬ Hidden Markov Model láº¡i lÃ  1 mÃ´ hÃ¬nh há»c mÃ¡y thá»‘ng kÃª cá»• Ä‘iá»ƒn nhÆ°ng Ä‘Ã£ vÃ  Ä‘ang Ä‘Æ°á»£c á»©ng dá»¥ng ráº¥t nhiá»u trong thá»±c tiá»…n. Xin má»i cáº£ nhÃ  Ä‘áº¿n tham dá»± vÃ  tháº£o luáº­n Ä‘á»ƒ hiá»ƒu sÃ¢u thÃªm vá» 2 thuáº­t toÃ¡n ráº¥t hay nÃ y.</p>

<ul>
<li>Thá»i gian: 14h~18h thá»© 7 - 29/9/2018 (má»Ÿ cá»­a Ä‘Ã³n khÃ¡ch 13h40 ~ 13h55)</li>
<li>Äá»‹a Ä‘iá»ƒm: Microsoft Japan office táº§ng 30
108-0075 æ±äº¬éƒ½æ¸¯åŒºæ¸¯å— 2-16-3 å“å·ã‚°ãƒ©ãƒ³ãƒ‰ã‚»ãƒ³ãƒˆãƒ©ãƒ«ã‚¿ãƒ¯ãƒ¼
<a href="https://www.microsoft.com/ja-jp/mscorp/branch/sgt.aspx">https://www.microsoft.com/ja-jp/mscorp/branch/sgt.aspx</a></li>
</ul>

<p>HÆ°á»›ng dáº«n: tá»« ga Shinagawa Ä‘i theo skywalker lÃ  Ä‘áº¿n chá»— reception (táº§ng 2). Táº¡i Ä‘Ã¢y báº¡n sáº½ láº¥y vÃ© vÃ o vÃ  lÃªn táº§ng 30.</p>

<p>ChÃº Ã½ vÃ¬ váº¥n Ä‘á» an ninh cá»§a toÃ  nhÃ  lÃ  yÃªu cáº§u Ä‘Äƒng kÃ½ trÆ°á»›c thÃ´ng tin há» tÃªn vÃ  email nÃªn báº¡n nÃ o tham gia xin vui lÃ²ng Ä‘iá»n thÃ´ng tin theo form dÆ°á»›i Ä‘Ã¢y. Háº¡n cuá»‘i Ä‘Äƒng kÃ½ lÃ  23:59 thá»© 2 - 24/9/2018.</p>

<p><a href="https://goo.gl/forms/IjkUdmR39LOAsRwe2">https://goo.gl/forms/IjkUdmR39LOAsRwe2</a></p>

<p>Ai khÃ´ng ká»‹p Ä‘Äƒng kÃ½ trÆ°á»›c thá»i háº¡n trÃªn sáº½ khÃ´ng Ä‘Æ°á»£c vÃ o toÃ  nhÃ  nÃªn ngoÃ i áº¥n Going thÃ¬ cÃ¡c báº¡n nhá»› Ä‘iá»n vÃ o form trÃªn nhÃ©. ThÃªm ná»¯a lÃ  viá»‡c vÃ o toÃ  nhÃ  khÃ´ng dá»… dÃ ng nÃªn cÃ¡c báº¡n tÃ­nh toÃ¡n thá»i gian cáº©n tháº­n Ä‘á»ƒ Ä‘áº¿n Ä‘Ãºng giá» nhÃ©.</p>

<p>Háº¹n gáº·p láº¡i cáº£ nhÃ  vÃ o buá»•i sáº¯p tá»›i!</p>

<h2 id="ná»™i-dung-chÆ°Æ¡ng-trÃ¬nh">&mdash;&ndash;Ná»™i dung chÆ°Æ¡ng trÃ¬nh:&mdash;&ndash;</h2>

<p>Speaker: Nguyen Phuoc Tat Dat (BizReach, Inc.)
Title: An introduction to Mask-RCNN
Description:
Instance Segmentation is an interesting and challenging task in Computer Vision. Besides detecting the bounding boxes to allocate each individual objects and their object types, this task also returns the binary masks that indicate which pixel belongs to the objects. In this seminar, we will discuss about Mask-RCNN, one of the state-of-the-art methods for Instance Segmentation. After a brief introduction, we will dive into the design of Mask RCNN neural network architecture. Finally, we will enjoy a demonstration to see how Mask-RCNN segments our faces, our bodies and our stuffs in realtime.</p>

<hr />

<p>Speaker: khanhtc
Title: HMM at a glance
Description: :
Hidden Markov Models are ubiquitous tool for modelling time series data. They are used in almost all current speech recognition systems, in numerous applications in computational molecular biology, in data compression, and in other areas of artificial intelligence and pattern recognition. In this session, we are going to look at the question &ldquo;what are Hidden Markov Models?&rdquo; and play around with this in some real life examples.</p>
</div>
    
    <div class="col-12 col-md-6 mb-2 ">

<p><strong>Paper Reading Festival: Summer 2018</strong></p>

<p>MÃ¹a hÃ¨ 2018 Ä‘Ã£ vÃ  Ä‘ang diá»…n ra ráº¥t sÃ´i Ä‘á»™ng vá»›i hÃ ng loáº¡t cÃ¡c top conference liÃªn quan Ä‘áº¿n AI/Machine Learning. ÄÃ¡p á»©ng láº¡i yÃªu cáº§u cá»§a nhiá»u báº¡n trong group, láº§n nÃ y chÃºng ta sáº½ cÃ³ 1 chÆ°Æ¡ng trÃ¬nh Ä‘áº·c biá»‡t vá»›i chá»§ Ä‘á» Paper Reading.</p>

<p>Ná»™i dung: má»—i presenter sáº½ giá»›i thiá»‡u vá» 1 paper chá»n tá»« top conference Ä‘Ã£ diá»…n ra trong thá»i gian gáº§n Ä‘Ã¢y (CVPR, ICML, ACL, IJCAI) trong thá»i gian 30 phÃºt bao gá»“m cáº£ QA. Má»¥c tiÃªu lÃ  Ä‘á»ƒ giÃºp má»i ngÆ°á»i cÃ¹ng cáº­p nháº­t cÃ¡c nghiÃªn cá»©u má»›i nháº¥t trong ngÃ nh.</p>

<p>Thá»i gian: Chá»§ nháº­t 19/8/2017 14:00 ~ 18:00
Äá»‹a Ä‘iá»ƒm: Cookpad Inc.
æ±äº¬éƒ½æ¸‹è°·åŒºæµæ¯”å¯¿4-20-3ã€€æµæ¯”å¯¿ã‚¬ãƒ¼ãƒ‡ãƒ³ãƒ—ãƒ¬ã‚¤ã‚¹ã‚¿ãƒ¯ãƒ¼12F
<a href="https://info.cookpad.com/corporate/access">https://info.cookpad.com/corporate/access</a></p>

<p>ChÆ°Æ¡ng trÃ¬nh dá»± kiáº¿n:</p>

<hr />

<h2 id="13h30-14h-má»Ÿ-cá»­a-Ä‘Ã³n-tiáº¿p-speaker-chuáº©n-bá»‹-mÃ¡y-chiáº¿u">13h30~14h: má»Ÿ cá»­a Ä‘Ã³n tiáº¿p + speaker chuáº©n bá»‹ mÃ¡y chiáº¿u</h2>

<p>14h~14h05:  giá»›i thiá»‡u chÆ°Æ¡ng trÃ¬nh</p>

<p>14h05~14h35:
Äá»— Minh Háº£i - [ICML] Learning Longer-term Dependencies in RNNs with Auxiliary Losses
<a href="http://proceedings.mlr.press/v80/trinh18a/trinh18a.pdf">http://proceedings.mlr.press/v80/trinh18a/trinh18a.pdf</a></p>

<p>14h35~15h05:
Pháº¡m Quang Khang - [CVPR] MobileNetV2: Inverted Residuals and Linear Bottlenecks
<a href="http://openaccess.thecvf.com/content_cvpr_2018/papers/Sandler_MobileNetV2_Inverted_Residuals_CVPR_2018_paper.pdf">http://openaccess.thecvf.com/content_cvpr_2018/papers/Sandler_MobileNetV2_Inverted_Residuals_CVPR_2018_paper.pdf</a></p>

<p>15h05~15h35:
Tráº§n CÃ´ng Khanh - [ACL] Learning to Control the Specificity in Neural Response Generation
<a href="http://aclweb.org/anthology/P18-1102">http://aclweb.org/anthology/P18-1102</a></p>

<hr />

<h2 id="15h35-15h50-nghá»‰-giáº£i-lao">15h35~15h50: nghá»‰ giáº£i lao</h2>

<p>15h50~16h20:
Nguyá»…n Tuáº¥n DÆ°Æ¡ng - [ICML] Fixing a broken ELBO <a href="https://arxiv.org/abs/1711.00464">https://arxiv.org/abs/1711.00464</a>
hoáº·c Concept activation vector <a href="https://arxiv.org/abs/1711.11279">https://arxiv.org/abs/1711.11279</a></p>

<p>16h20~16h50:
Nguyá»…n Äáº¡t - [ACL] Simple and Effective Multi-Paragraph Reading Comprehension
<a href="http://aclweb.org/anthology/P18-1078">http://aclweb.org/anthology/P18-1078</a></p>

<hr />

<h2 id="16h50-17h-nghá»‰-giáº£i-lao">16h50~17h: nghá»‰ giáº£i lao</h2>

<p>17h~17h30:
Phong Nguyá»…n - [ICML] Visualizing and Understanding Atari Agents
<a href="http://proceedings.mlr.press/v80/greydanus18a.html">http://proceedings.mlr.press/v80/greydanus18a.html</a></p>

<p>17h30~18h:
VÄƒn PhÃº Quang Huy - [ACL] Hierarchical Neural Story Generation <a href="http://aclweb.org/anthology/P18-1082">http://aclweb.org/anthology/P18-1082</a></p>
</div>
    
    <div class="col-12 col-md-6 mb-2 "><p>ğŸ—¾ ThÃ¡ng 12 nÃ y táº¡i xá»© sá»Ÿ máº·t trá»i má»c, VN Geeks sáº½ chÃ­nh thá»©c mang VN Techconnect trá»Ÿ láº¡i vá»›i cá»™ng Ä‘á»“ng IT Viá»‡t Nam. Váº«n giá»¯ trá»n nhá»¯ng giÃ¡ trá»‹ lÃ m nÃªn thÃ nh cÃ´ng cá»§a sá»± kiá»‡n Ä‘áº§u tiÃªn, VN Techconnect 2018 há»©a háº¹n sáº½ háº¥p dáº«n hÆ¡n ná»¯a nhá» nhá»¯ng Ä‘á»•i má»›i &ldquo;Ä‘áº¯t giÃ¡&rdquo;.</p>

<p>ğŸ¤ TECHTALK - &ldquo;Cá»• mÃ  khÃ´ng cÅ©&rdquo;<br />
HÃ¬nh thá»©c láº¯ng nghe diá»…n giáº£ truyá»n Ä‘áº¡t thÃ´ng tin cÃ¹ng pháº§n há»i Ä‘Ã¡p Q&amp;A Ä‘Ã£ trá»Ÿ nÃªn háº¿t sá»©c phá»• biáº¿n. ÄÃ¢y lÃ  cÃ¡ch tá»‘t nháº¥t Ä‘á»ƒ khÃ¡n giáº£ tham dá»± cÃ³ thá»ƒ tiáº¿p nháº­n thÃ´ng tin, Ä‘á»“ng thá»i trá»±c tiáº¿p Ä‘Æ°á»£c giáº£i Ä‘Ã¡p cÃ¡c tháº¯c máº¯c cá»§a báº£n thÃ¢n bá»Ÿi nhá»¯ng chuyÃªn gia trong ngÃ nh.<br />
Táº¡i VN Techconnect 2018, Techtalk sáº½ tiáº¿p tá»¥c Ä‘Ã³ng má»™t vai trÃ² chÃ­nh trong chÆ°Æ¡ng trÃ¬nh. Vá»›i trá»ng tÃ¢m lÃ  Artificial Intelligence (AI), Techtalk sáº½ Ä‘Æ°á»£c Ä‘áº£m nháº­n bá»Ÿi thÃ nh viÃªn nhá»¯ng Ä‘Æ¡n vá»‹ AI ná»•i tiáº¿ng táº¡i Nháº­t Báº£n - há»©a háº¹n mang láº¡i nhá»¯ng chia sáº» há»¯u Ã­ch vÃ  má»›i máº» nháº¥t cho báº¡n.</p>

<p>ğŸ† BUSINESS CONTEST - &ldquo;Sá»©c sá»‘ng má»›i&rdquo; cá»§a VN Techconnect 2018<br />
Má»™t sá»± kiá»‡n dÃ¹ thÃ nh cÃ´ng Ä‘áº¿n Ä‘Ã¢u cÅ©ng sáº½ trá»Ÿ nÃªn phai nháº¡t trong tÃ¢m trÃ­ cá»™ng Ä‘á»“ng náº¿u khÃ´ng cÃ³ nhá»¯ng thay Ä‘á»•i vÃ  cáº£i tiáº¿n phÃ¹ há»£p. Hiá»ƒu rÃµ Ä‘iá»u nÃ y, VN Geeks quyáº¿t Ä‘á»‹nh thá»•i má»™t lÃ n giÃ³ má»›i vÃ o &ldquo;Ä‘á»©a con tinh tháº§n&rdquo; VN Techconnect vá»›i Business Contest - cuá»™c thi Ã½ tÆ°á»Ÿng sáº£n pháº©m AI dÃ nh cho cÃ¡c ká»¹ sÆ° IT táº¡i Nháº­t.<br />
Vá»›i nhá»¯ng giáº£i thÆ°á»Ÿng háº¥p dáº«n vÃ  sá»± gÃ³p máº·t cá»§a ban giÃ¡m kháº£o lÃ  cÃ¡c nhÃ  Ä‘áº§u tÆ°, co-founder cÃ´ng nghá»‡ cao táº¡i Nháº­t Báº£n, Hoa Ká»³, Business Contest sáº½ lÃ  Ä‘iá»ƒm sÃ¡ng mang Ä‘áº¿n má»™t VN Techconnect má»›i máº» hÆ¡n, thu hÃºt hÆ¡n háº³n so vá»›i &ldquo;phiÃªn báº£n&rdquo; 2017.</p>

<p>ğŸŒŸ Nhá»¯ng ai nÃªn tham dá»± VN Techconnect 2018: Power of AI?<br />
- Ká»¹ sÆ° IT Viá»‡t Nam á»Ÿ Tokyo.
- NgÆ°á»i Viá»‡t cÃ³ Ä‘am mÃª vá»›i Machine Learning vÃ  AI táº¡i Tokyo.</p>

<p>ğŸ‘‰ Ná»˜I DUNG CHÆ¯Æ NG TRÃŒNH
ğŸŒ± Techtalk
- Chia sáº», tá»a Ä‘Ã m vá» táº§m áº£nh hÆ°á»Ÿng, á»©ng dá»¥ng cá»§a AI táº¡i Nháº­t Báº£n vÃ  tháº¿ giá»›i.
- ÄÃ¡nh giÃ¡ vá» thá»±c tráº¡ng vÃ  triá»ƒn vá»ng cÃ¡c dá»± Ã¡n AI táº¡i Viá»‡t nam.
ğŸŒ± Business Contest<br />
- Cuá»™c thi Ã½ tÆ°á»Ÿng sáº£n pháº©m AI dÃ nh cho cÃ¡c kÄ© sÆ° Viá»‡t Nam táº¡i Nháº­t.</p>

<p>ğŸ‘‰ ÄÄ‚NG KÃ BUSINESS CONTEST
Truy cáº­p vÃ  Ä‘iá»n thÃ´ng tin vÃ o form: <a href="https://goo.gl/forms/2wEaf4rcvjGDXGLh2">https://goo.gl/forms/2wEaf4rcvjGDXGLh2</a>
hoáº·c quÃ©t mÃ£ QR trong áº£nh
ğŸ“ Háº¡n Ä‘Äƒng kÃ­: 23h59 ngÃ y 17/11/2018 (Giá» Nháº­t Báº£n)
ğŸ“ Háº¡n ná»™p Ã½ tÆ°á»Ÿng (slide/demo/video): 23h59 ngÃ y 24/11/2018 (Giá» Nháº­t Báº£n).
Ban tá»• chá»©c sáº½ chá»n ra 8 Ä‘á»™i tá»‘t nháº¥t Ä‘á»ƒ trÃ¬nh bÃ y táº¡i sá»± kiá»‡n.
Káº¿t quáº£ vÃ²ng sÆ¡ loáº¡i, sáº½ Ä‘Æ°á»£c thÃ´ng bÃ¡o vÃ o ngÃ y 28/11/2018 qua email cÃ¡c Ä‘á»™i Ä‘Äƒng kÃ½ trong form.</p>

<p>GIáº¢I THÆ¯á»NG Háº¤P DáºªN
ğŸ“ Nháº­n khoáº£n tiá»n thÆ°á»Ÿng lá»›n (tá»•ng giáº£i thÆ°á»Ÿng trá»‹ giÃ¡ 18 man, trong Ä‘Ã³ giáº£i nháº¥t trá»‹ giÃ¡ 10 man) ğŸ’°
ğŸ“ ÄÆ°á»£c trao Ä‘á»•i vÃ  hoÃ n thiá»‡n Ã½ tÆ°á»Ÿng vá»›i Ä‘á»™i ngÅ© BGK (BGK lÃ  cÃ¡c nhÃ  Ä‘áº§u tÆ° lá»›n vÃ  giÃ u kinh nghiá»‡m, thÃ´ng tin chi tiáº¿t sáº½ Ä‘Æ°á»£c báº­t mÃ­ á»Ÿ nhá»¯ng post tá»›i) ğŸ”Š
ğŸ“ CÃ³ thá»ƒ nháº­n Ä‘Æ°á»£c Ä‘áº§u tÆ° vÃ  cÃ³ nhiá»u cÆ¡ há»™i phÃ¡t triá»ƒn sá»± nghiá»‡p (khÃ´ng chá»‰ giáº£i thÆ°á»Ÿng tiá»n máº·t mÃ  nhá»¯ng Ã½ tÆ°á»Ÿng hay cÃ²n nháº­n Ä‘Æ°á»£c nhá»¯ng cÆ¡ há»™i mang tÃ­nh lÃ¢u dÃ i trong tÆ°Æ¡ng lai) ğŸ’­</p>

<p>TIÃŠU CHÃ ÄÃNH GIÃ
ğŸ“ TÃ­nh vÄ© mÃ´: Bá»©c tranh tháº¿ giá»›i trá»Ÿ nÃªn nhÆ° tháº¿ nÃ o khi sáº£n pháº©m hay dá»‹ch vá»¥ Ä‘Ã³ ra Ä‘á»i?
ğŸ“ CÆ¡ sá»Ÿ lÃ½ thuyáº¿t
ğŸ“ TÃ­nh kháº£ thi
ğŸ“ TÃ­nh cáº¡nh tranh</p>

<p>ğŸ‘‰ THÃ”NG TIN CHI TIáº¾T<br />
Thá»i gian: 1/12/2018
Äá»‹a Ä‘iá»ƒm: Speee Inc., 4th floor, Kurosaki building, Roppongi 4-1-4, Minato-ku, Tokyo
Link Ä‘Äƒng kÃ½ Business Contest: <a href="https://goo.gl/forms/2wEaf4rcvjGDXGLh2">https://goo.gl/forms/2wEaf4rcvjGDXGLh2</a></p>

<p>ğŸ–‚ Má»i cÃ¢u há»i xin vui lÃ²ng liÃªn há»‡ qua:
Facebook: <a href="https://bit.ly/2xGkHel">https://bit.ly/2xGkHel</a>
Email: vngeek.contact@gmail.com</p>
</div>
    
  </div>
</div>

  </div>

  <div class="footer">
  <div class="container">
    <div class="row">
      <div class="col-12">
        <div class="footer-inner">
          <h3 class="footer-title">VJAI - Cá»™ng Ä‘á»“ng AI Viá»‡t Nam táº¡i Nháº­t Báº£n</h3>
          <ul class="footer-menu">
            <li><a href="https://vjai.jp">Home</a></li>
            <li><a href="https://vjai.jpcontact">Contact</a></li>
            <li class="copyright">Â© 2019 VJAI - Cá»™ng Ä‘á»“ng AI Viá»‡t Nam táº¡i Nháº­t Báº£n</li>
          </ul>
        </div>
      </div>
    </div>
  </div>
</div>
  <div class="sub-footer">
    <div class="container">
      <div class="row">
        <div class="col-12">
          <div class="sub-footer-inner">
            <ul>
              
              <li><strong>Email: </strong><a href="mailto:info@vjai.jp">
                  info@vjai.jp</a></li>
            </ul>
            <ul>
              <li class="zerostatic"><a href="https://vjai.jp">vjai.jp</a></li>
            </ul>
          </div>
        </div>
      </div>
    </div>
  </div>

  

  
  

  
  <script type="text/javascript" src="/js/scripts.min.bf1e1f7ae8e03db5f012356e825843facdff51c0a559cb0d27fe2bbe1db405c2.js"></script>
  

  






</body>
</html>